# inference options
model_type: EEND
chunk_size: 2000000
gpu: 1

