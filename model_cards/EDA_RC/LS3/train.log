[ INFO : 2022-03-25 14:41:11,387 ] - namespace(config=[<yamlargparse.Path object at 0x7f497c66ba60>], config2=None, feature_config=[<yamlargparse.Path object at 0x7f497c673970>], train_data_dir='data/LibriSpeech/data/train_clean_360_ns3_beta8_100000', valid_data_dir='data/LibriSpeech/data/dev_clean_ns3_beta8_500', model_save_dir='exp/LibriSpeech_3/EDA_RC/gradclip_5_batchsize_32_num_frames_500_adam_lr_1e-5_noam_warmup_steps_100000_fix_bug_global/models', model_type='EDA_RC', initmodel='', resume=13, gpu=2, max_epochs=20, input_transform='logmel23_mn', lr=1e-05, optimizer='adam', num_speakers=3, gradclip=5, num_frames=500, batchsize=32, label_delay=0, hidden_size=256, in_size=None, rnn_cell='LSTM', chunk_size=50, shuffle_rate=0.0, inherit_from='./exp/LibriSpeech_3/EEND_EDA/gradclip_5_batchsize_32_num_frames_500_noam_lr_1.0_noam_warmup_steps_100000/models/avg.th', loss_factor=None, context_size=7, subsampling=10, frame_size=200, frame_shift=80, sampling_rate=8000, noam_warmup_steps=100000.0, transformer_encoder_n_heads=4, transformer_encoder_n_layers=4, transformer_encoder_dropout=0.1, gradient_accumulation_steps=1, seed=777)
[ INFO : 2022-03-25 14:41:40,094 ] - Prepared model
[ INFO : 2022-03-25 14:41:40,095 ] - DataParallel(
  (module): EDA_RC(
    (encoder): Linear(in_features=345, out_features=256, bias=True)
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (decoder): eda_spk_extractor(
      (rnn_encoder): LSTM(256, 256, batch_first=True)
      (attractor): LSTM(256, 256, batch_first=True)
      (discriminator): Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Sigmoid()
      )
      (project): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (spk_emb_extractor): TransformerDecoder(
      (layers): ModuleList(
        (0): TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (rnn_cluster): RNN_Clusterer(
      (mixer): GRUCell(256, 256)
      (pred): Bilinear(in1_features=256, in2_features=256, out_features=1, bias=True)
    )
  )
)
[ INFO : 2022-03-25 14:41:40,600 ] - Load model from exp/LibriSpeech_3/EDA_RC/gradclip_5_batchsize_32_num_frames_500_adam_lr_1e-5_noam_warmup_steps_100000_fix_bug_global/models/transformer13.th
[ INFO : 2022-03-26 04:08:47,528 ] - Epoch:  14, LR: 0.0000100,            Training Loss: 0.09118/0.09799/0.14520/0.07265/0.43717, Dev Stats: {'speech_scored': 353.41, 'speech_miss': 22.15, 'speech_falarm': 3.86, 'speaker_scored': 535.18, 'speaker_miss': 41.9, 'speaker_falarm': 17.72, 'speaker_error': 7.03, 'correct': 436.49, 'diarization_error': 66.65, 'frames': 461.05, 'DER': 12.45, 'change_recall': 0.0, 'change_precision': 0.0, 'num_pred_acc': 0.0}
[ INFO : 2022-03-26 10:26:50,582 ] - Epoch:  15, LR: 0.0000100,            Training Loss: 0.08838/0.09847/0.14353/0.07307/0.43644, Dev Stats: {'speech_scored': 353.41, 'speech_miss': 17.99, 'speech_falarm': 4.21, 'speaker_scored': 535.18, 'speaker_miss': 34.93, 'speaker_falarm': 20.81, 'speaker_error': 6.15, 'correct': 438.38, 'diarization_error': 61.89, 'frames': 461.05, 'DER': 11.56, 'change_recall': 0.0, 'change_precision': 0.0, 'num_pred_acc': 0.0}
[ INFO : 2022-03-26 16:45:08,394 ] - Epoch:  16, LR: 0.0000100,            Training Loss: 0.08430/0.10047/0.14474/0.07374/0.43884, Dev Stats: {'speech_scored': 353.41, 'speech_miss': 19.76, 'speech_falarm': 3.47, 'speaker_scored': 535.18, 'speaker_miss': 38.47, 'speaker_falarm': 17.55, 'speaker_error': 6.31, 'correct': 438.17, 'diarization_error': 62.33, 'frames': 461.05, 'DER': 11.65, 'change_recall': 0.0, 'change_precision': 0.0, 'num_pred_acc': 0.0}
[ INFO : 2022-03-26 23:05:30,115 ] - Epoch:  17, LR: 0.0000100,            Training Loss: 0.08445/0.09934/0.14050/0.07277/0.43456, Dev Stats: {'speech_scored': 353.41, 'speech_miss': 18.22, 'speech_falarm': 3.84, 'speaker_scored': 535.18, 'speaker_miss': 36.88, 'speaker_falarm': 18.12, 'speaker_error': 6.48, 'correct': 438.4, 'diarization_error': 61.48, 'frames': 461.05, 'DER': 11.49, 'change_recall': 0.0, 'change_precision': 0.0, 'num_pred_acc': 0.0}
[ INFO : 2022-03-27 05:45:52,804 ] - Epoch:  18, LR: 0.0000100,            Training Loss: 0.08022/0.09974/0.13752/0.07289/0.43472, Dev Stats: {'speech_scored': 353.41, 'speech_miss': 19.07, 'speech_falarm': 3.83, 'speaker_scored': 535.18, 'speaker_miss': 35.83, 'speaker_falarm': 18.74, 'speaker_error': 6.31, 'correct': 438.66, 'diarization_error': 60.88, 'frames': 461.05, 'DER': 11.37, 'change_recall': 0.0, 'change_precision': 0.0, 'num_pred_acc': 0.0}
[ INFO : 2022-03-27 11:04:44,235 ] - Epoch:  19, LR: 0.0000100,            Training Loss: 0.08100/0.09946/0.13821/0.07282/0.43249, Dev Stats: {'speech_scored': 353.41, 'speech_miss': 14.78, 'speech_falarm': 4.0, 'speaker_scored': 535.18, 'speaker_miss': 31.17, 'speaker_falarm': 21.19, 'speaker_error': 6.25, 'correct': 439.44, 'diarization_error': 58.6, 'frames': 461.05, 'DER': 10.95, 'change_recall': 0.0, 'change_precision': 0.0, 'num_pred_acc': 0.0}
[ INFO : 2022-03-27 16:53:03,503 ] - Epoch:  20, LR: 0.0000100,            Training Loss: 0.07962/0.09963/0.13627/0.07290/0.43121, Dev Stats: {'speech_scored': 353.41, 'speech_miss': 16.85, 'speech_falarm': 3.88, 'speaker_scored': 535.18, 'speaker_miss': 34.28, 'speaker_falarm': 19.77, 'speaker_error': 6.45, 'correct': 438.74, 'diarization_error': 60.5, 'frames': 461.05, 'DER': 11.31, 'change_recall': 0.0, 'change_precision': 0.0, 'num_pred_acc': 0.0}
[ INFO : 2022-03-27 16:53:06,897 ] - Finished!
